{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4351d4-9e67-43e3-8ac4-827349c61d94",
   "metadata": {},
   "source": [
    "# Model Evaluation and Hyperparameter\n",
    "\n",
    "Hyperparameter are \"higher-level\" free parameters.\n",
    "- Depth (number of hidden layers)\n",
    "- Width (number of hidden neurons in a hidden layer)\n",
    "- Activation function (choice of nonlinearity in non-input nodes)\n",
    "- Regularization parameter (way to trade off simplicity vs. fit to the data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00039c-ff2c-4048-ab29-33853d87cf4a",
   "metadata": {},
   "source": [
    "Recall\n",
    "\n",
    "A predictor obtained by training the free parameters of the considered model using the available annotated data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e626a-4da2-48bf-a29d-2efb0a52b9d9",
   "metadata": {},
   "source": [
    "## How to Choose a Model\n",
    "\n",
    "It is not to evaluate if a chosen model is good or not (performs well in training and in real practice)\n",
    "\n",
    "Validation methods (validation set):\n",
    "- Holdout validation\n",
    "- Cross-validation\n",
    "- Leave-one-out validation\n",
    "\n",
    "## Holdout Validation\n",
    "- Randomly choose 30% of data to form a validaton set\n",
    "- Remaining data forms the training set\n",
    "- Estimate the test performance on the validation set against all candidate models\n",
    "    - Regression: Compute the cost function (such MSE) on the validation set (instead of the training set)\n",
    "    - Classification: Compute the 0 - error metric:\n",
    "    $ \\frac{number of wrong predictions}{number of predictions} = 1 - Accuracy $\n",
    "- Choose the model with the lowest validation error (such as lowest MSE)\n",
    "- Re-train with chosen model on joined training and validation to obtain predictor\n",
    "- Estimate future performance of the obtained predictor on test set\n",
    "- Ready to deploy with the predictor\n",
    "\n",
    "### k-Fold Cross-Validation\n",
    "\n",
    "<pre>\n",
    "Full Dataset\n",
    "│\n",
    "├──> Split once --> Train+Validation Set (80%)       Test Set (20%)\n",
    "                     │\n",
    "                     └──> K-Fold Cross-Validation (e.g., k=5)\n",
    "                          ┌────┬────┬────┬────┬────┐\n",
    "                          │ F1 │ F2 │ F3 │ F4 │ F5 │   <- folds\n",
    "                          └────┴────┴────┴────┴────┘\n",
    "     Iteration 1: Train on F2–F5, Validate on F1\n",
    "     Iteration 2: Train on F1, F3–F5, Validate on F2\n",
    "     ...\n",
    "     Iteration 5: Train on F1–F4, Validate on F5\n",
    "</pre>\n",
    "\n",
    "After CV: Pick best hyperparameters → retrain on all 80%\n",
    "Evaluate once on the 20% Test Set → final model performance\n",
    "\n",
    "<img src=\"images/k-fold.png\" width=\"450\" />\n",
    "\n",
    "- Split the training set randomly into k (equal-sized) disjoint sets\n",
    "- Use k - 1 of those together for training\n",
    "- Use the remaining one for validation\n",
    "- Permuate the k sets and repeat k times\n",
    "- Average the performances on k validation sets\n",
    "  - Take the mean of all k errors: $MSE_3fold = 2.05$\n",
    "- Repeat for all candidate models\n",
    "- Choose the model with the smallest average 3-fold cross validation error.\n",
    "- Re-train with chose model on joined training and validation to obtain the predictor\n",
    "- Estimate future performance of the obtained predictor on test set\n",
    "- Deploy the predictor in real-world\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120dcfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1, 'kernel': 'linear'}\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# 1. Split into training+validation and test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define model and hyperparameter grid\n",
    "model = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# 3. GridSearchCV performs k-fold CV (default k=5)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_trainval, y_trainval)\n",
    "\n",
    "# 4. Best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# 5. Final test set evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac6b4e4",
   "metadata": {},
   "source": [
    "\n",
    "### Leave-one-out Validation\n",
    "\n",
    "- Leave a single example for validation, and train on all the rest of the annotated data\n",
    "- For a total of N examples, repeat this N times, each time leaving out a single example\n",
    "- Take the average of the validation errors as measured on the left-out points\n",
    "- Same as N-fold cross-validation where N is the number of labelled points\n",
    "\n",
    "<img src=\"images/validation-methods.png\" width=\"500\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24209bb6-9380-4079-83a5-99a5991318c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
