{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee614e90-81d0-4842-bd9f-f185268e6785",
   "metadata": {},
   "source": [
    "### Unsupervised Learning\n",
    "\n",
    "#### Supervised Learning\n",
    "- Labeled observations: Each observation is a tuple (x, y) of feature vector x and output label y which are related according to an unknown function f (x) = y.\n",
    "- During training: Use the labeled observations to learn the relationship between x and y , i.e., find a function (or model) h(x) that best fits the observations\n",
    "- Goal: Ensure that the learned model h(x) accurately predicts the output label of a previously unseen, test feature input (generalization)\n",
    "- Labels : ‘Teachers’ during training, and ‘validator’ of results during testing\n",
    "\n",
    "#### Unsupervised Learning (Clustering)\n",
    "- Unlabeled data set of feature vectors\n",
    "- Clustering: Find sub-groups or clusers among feature vectors with similar traits\n",
    "- Dimensionality Reduction: Find patterns within feature vector to identify a lower dimensional representation\n",
    "  - eg. Image compression\n",
    "- Examples: market segmentation, social network analysis\n",
    "- Motivation:\n",
    "  - Abundance of unlabeled data\n",
    "  - Compressed representation saves on storage and computation\n",
    "  - Reduce noise, irrelevant attributes in high dimensional data\n",
    "  - Pre-processing step for supervised learning\n",
    "  - Often used more in exploratory data analysis\n",
    "\n",
    "#### Clustering\n",
    "\n",
    "- Goal: Find natural groupings among observations/objects/feature vectors\n",
    "- Segment observations into clusters/groups such that\n",
    "    - Objects within a cluster have high similarity (high intra-cluster similarity)\n",
    "    - Objects across clusters have low similarity (low inter-cluster similarity)\n",
    "\n",
    "##### Proximity Indices\n",
    "\n",
    "It is used to quantify the strength of relationship between any two feature vectors.\n",
    "- Continuous-valued featuers\n",
    "    - e.g. x = (0.1, 11, 15, 1.5), measure the `distance` between any two values\n",
    "    - Euclidean distance # TODO write the math function\n",
    "    - Manhattan distance\n",
    "    - Chebychev distance\n",
    "\n",
    "- Different choice of distance functions yields different measures of similarity.\n",
    "- Distance functions implicitly assign more weighting to features with large ranges than to those with small ranges.\n",
    "- Rule of thumb: When no a priori domain knowledge is available, clustering should follow the principle of equal weightings to each attribute\n",
    "- This necessitates feature scaling of vectors.\n",
    "\n",
    "\n",
    "##### Feature Scaling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b715ac4-5341-4ca2-a8dd-aba981da026e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb831e3-711a-4696-9de3-f3af041f3b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_study)",
   "language": "python",
   "name": "ml_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
