{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot\n",
    "\n",
    "“One-shot” can mean different things depending on the context in NLP or AI embeddings.\n",
    "\n",
    "## One-Shot in NLP (One-Hot Encoding)\n",
    "\n",
    "In NLP, one-shot vector often refers to one-hot encoding, a method of representing categorical data (such as words in a vocabulary) as binary vectors.\n",
    "\n",
    "Example:\n",
    "\n",
    "If your vocabulary consists of three words: [\"cat\", \"dog\", \"fish\"], then one-hot encoding represents them as:\n",
    "- “cat” → [1, 0, 0]\n",
    "- “dog” → [0, 1, 0]\n",
    "- “fish” → [0, 0, 1]\n",
    "\n",
    "Each word gets a unique position in a high-dimensional space, but this approach has limitations:\n",
    "- Sparse representation (most elements are 0).\n",
    "- No notion of similarity (e.g., “dog” and “wolf” are equally distant as “dog” and “table”).\n",
    "\n",
    "That’s why word embeddings (like Word2Vec, GloVe, or BERT) are often preferred over one-hot encoding.\n",
    "\n",
    "## One-Shot in AI Embeddings\n",
    "\n",
    "In AI, particularly in few-shot learning and one-shot learning, “one-shot” has a different meaning.\n",
    "\n",
    "### One-Shot Learning\n",
    "\n",
    "One-shot learning refers to a model’s ability to recognize or classify new data points with just one example per class. This is common in:\n",
    "- Facial recognition: A system learns your face from just one photo and can recognize you later.\n",
    "- Image classification: Identifying a new object with minimal examples.\n",
    "\n",
    "Oneshot learning relies on embedding-based methods, such as:\n",
    "- Siamese networks: Compare similarity between embeddings of different data points.\n",
    "- Triplet loss: Ensures embeddings of similar items are closer together.\n",
    "- Transformer models: Few-shot capabilities in NLP.\n",
    "\n",
    "### Embeddings and One-Shot Learning\n",
    "\n",
    "Embeddings convert data (like words, sentences, or images) into dense vector representations in a continuous space, where similar data points are closer together.\n",
    "\n",
    "For example, a word embedding model (like Word2Vec or BERT) represents:\n",
    "- “king” as [0.5, 0.1, -0.3, …]\n",
    "- “queen” as [0.49, 0.12, -0.29, …]\n",
    "\n",
    "Unlike one-hot encoding, these embeddings capture semantic relationships."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
