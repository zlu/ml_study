{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Hill Climbing with Random Restarts\n",
    "Objective: Implement a hill climbing algorithm using random restarts.\n",
    "\n",
    "Problem Description: You are tasked with implementing a simple optimization algorithm called hill climbing. The goal is to find the maximum value of a given function within a specified range. If the algorithm reaches a local maximum, it should randomly restart from a new starting point.\n",
    "\n",
    "Key components:\n",
    "\n",
    "- start_point : Initial (x,y) coordinates\n",
    "- R : Number of random restarts (100)\n",
    "- I : Number of iterations per restart (1000)\n",
    "- perturbation_step : How much to perturb the solution in each step (0.5)\n",
    "\n",
    "The algorithm works as follows:\n",
    "\n",
    "1. Start from an initial point\n",
    "2. For each of the R restarts:\n",
    "   - For each of the I iterations:\n",
    "     - Generate a candidate solution by randomly perturbing the current solution\n",
    "     - If the candidate solution is better, update the best solution\n",
    "     - If we're stuck in a local maximum (no improvement for half the iterations), restart from a random point\n",
    "   - Keep track of the best solution found across all restarts\n",
    "Hill climbing is a local search algorithm that always moves in the direction of increasing value. The random restarts help escape local optima by occasionally jumping to a completely new location in the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution found: (-0.4991755614037574, -0.4974330806217897)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# Define the Rosenbrock function\n",
    "def f(x, y):\n",
    "    a = 1\n",
    "    b = 100\n",
    "    return (a - x)**2 + b * (x**2 - y)**2\n",
    "\n",
    "# Perform hill climbing with random restarts\n",
    "def hill_climbing_with_restarts(start_point, R=100, I=1000, perturbation_step=0.5):\n",
    "    best_solution = None\n",
    "    \n",
    "    for _ in range(R):\n",
    "        current_x, current_y = start_point\n",
    "        best_x, best_y = start_point\n",
    "        \n",
    "        for _ in range(I):\n",
    "            # Generate a candidate solution by perturbing the current solution\n",
    "            candidate_x = current_x + (random.uniform(-1, 1) * perturbation_step)\n",
    "            candidate_y = current_y + (random.uniform(-1, 1) * perturbation_step)\n",
    "            \n",
    "            if f(candidate_x, candidate_y) > f(best_x, best_y):\n",
    "                best_x, best_y = candidate_x, candidate_y\n",
    "            \n",
    "            # Check for local maximum\n",
    "            # If weâ€™re in the second half of the iterations (_ > I // 2) and the current function value is extremely close to the best-known value (within 1e-5 difference)\n",
    "            if _ > I // 2 and abs(f(current_x, current_y) - f(best_x, best_y)) < 1e-5:\n",
    "                start_point = (random.uniform(-3, 3), random.uniform(-3, 3))\n",
    "                break\n",
    "        \n",
    "        if best_solution is None or f(best_x, best_y) > f(best_solution[0], best_solution[1]):\n",
    "            best_solution = (best_x, best_y)\n",
    "    \n",
    "    return best_solution\n",
    "\n",
    "# Example usage\n",
    "start_point = (0, 0)\n",
    "result = hill_climbing_with_restarts(start_point)\n",
    "print(f\"Best solution found: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularized Objective Function for Knapsack Problem\n",
    "Objective: Modify the objective function of the knapsack problem to include a penalty term that accounts for constraint violation.\n",
    "\n",
    "Problem Description: Given a set of items with weights and values, you want to maximize the total value without exceeding a given weight limit. The new objective function should penalize solutions that exceed the weight limit.\n",
    "```python\n",
    "def F(v, c=1.0):\n",
    "    return f(v) - c * h(v)\n",
    "```\n",
    "Key components:\n",
    "\n",
    "- f(v) : Original objective function (maximize total value)\n",
    "- h(v) : Constraint penalty function (penalizes solutions that exceed weight limit)\n",
    "- F(v, c) : Regularized objective function that combines value and penalty\n",
    "- c is a regularization parameter that controls the strength of the penalty\n",
    "This approach is called \"penalty method\" or \"regularization\" because:\n",
    "\n",
    "1. It transforms a constrained optimization problem into an unconstrained one\n",
    "2. It allows the algorithm to explore solutions that might temporarily violate constraints\n",
    "3. As the parameter c increases, solutions that violate constraints are penalized more heavily\n",
    "The penalty function h(v) typically measures how much the total weight exceeds the maximum allowed weight. For example:\n",
    "h(v) = max(0, total_weight(v) - max_weight)\n",
    "This regularization approach allows the search algorithm to move through infeasible regions of the search space, which can sometimes lead to better final solutions than if we strictly enforced the constraint at every step.\n",
    "\n",
    "The algorithm:\n",
    "\n",
    "1. Define items with values and weights\n",
    "2. Define a maximum weight constraint\n",
    "3. Use hill climbing with random restarts to find the best solution\n",
    "4. For each iteration, flip one item's inclusion status (0 to 1 or 1 to 0)\n",
    "5. Accept the change if it improves the regularized objective function\n",
    "The regularization approach allows the algorithm to explore solutions that might slightly violate the weight constraint during the search, but eventually converge to a valid solution due to the penalty term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution found: [0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define the knapsack problem parameters\n",
    "items = [{'value': 60, 'weight': 10}, {'value': 100, 'weight': 20}, {'value': 120, 'weight': 30}]\n",
    "max_weight = 50\n",
    "\n",
    "# Define the original objective function\n",
    "def f(v):\n",
    "    total_value = 0\n",
    "    for i in range(len(items)):\n",
    "        if v[i]:\n",
    "            total_value += items[i]['value']\n",
    "    return total_value\n",
    "\n",
    "# Define the constraint penalty function\n",
    "def h(v):\n",
    "    total_weight = sum(items[i]['weight'] * v[i] for i in range(len(items)))\n",
    "    return max(total_weight - max_weight, 0)\n",
    "\n",
    "# Define the regularized objective function\n",
    "def F(v, c=1.0):\n",
    "    return f(v) - c * h(v)\n",
    "\n",
    "# Perform hill climbing with random restarts\n",
    "def hill_climbing_with_restarts(R=100, I=1000):\n",
    "    best_solution = None\n",
    "    \n",
    "    for _ in range(R):\n",
    "        current_solution = [random.choice([0, 1]) for _ in range(len(items))]\n",
    "        best_solution = current_solution\n",
    "        \n",
    "        for _ in range(I):\n",
    "            candidate_solution = current_solution[:]\n",
    "            i = random.randint(0, len(items) - 1)\n",
    "            candidate_solution[i] = 1 - candidate_solution[i]\n",
    "            \n",
    "            if F(candidate_solution) > F(best_solution):\n",
    "                best_solution = candidate_solution\n",
    "    \n",
    "    return best_solution\n",
    "\n",
    "# Example usage\n",
    "result = hill_climbing_with_restarts()\n",
    "print(f\"Best solution found: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated Annealing for Traveling Salesman Problem (TSP)\n",
    "Objective: Implement simulated annealing to solve the traveling salesman problem.\n",
    "\n",
    "Problem Description: Given a set of cities and distances between them, find the shortest possible route that visits each city exactly once and returns to the starting point. Use simulated annealing to minimize the total distance.\n",
    "\n",
    "Key components:\n",
    "\n",
    "- T0 : Initial temperature (1000)\n",
    "- alpha : Cooling rate (0.95)\n",
    "- I : Number of iterations per temperature (1000)\n",
    "The algorithm:\n",
    "\n",
    "1. Generate a random initial tour\n",
    "2. For each temperature level:\n",
    "   - For each iteration:\n",
    "     - Generate a candidate tour by swapping two random cities\n",
    "     - Calculate the change in distance (delta_D)\n",
    "     - If delta_D < 0 (improvement), accept the change\n",
    "     - If delta_D >= 0 (worse), accept with probability e^(-delta_D/T)\n",
    "   - Reduce temperature by multiplying by alpha\n",
    "Simulated annealing is inspired by the annealing process in metallurgy. The \"temperature\" parameter controls how likely the algorithm is to accept worse solutions. At high temperatures, it frequently accepts worse solutions, allowing it to explore the search space broadly. As the temperature decreases, it becomes more selective, eventually converging to a good solution.\n",
    "\n",
    "The key advantage of simulated annealing over hill climbing is its ability to escape local optima by occasionally accepting worse solutions, especially early in the search process.\n",
    "\n",
    "\n",
    "## Temperature in Simulated Annealing for TSP\n",
    "The term \"temperature\" in simulated annealing comes from the physical annealing process in metallurgy that inspired the algorithm:\n",
    "\n",
    "1. Physical Annealing : In metallurgy, annealing involves heating a material to a high temperature and then slowly cooling it to reduce defects and increase strength.\n",
    "2. Algorithm Analogy : In the algorithm, \"temperature\" is a control parameter that determines how likely the algorithm is to accept worse solutions:\n",
    "   \n",
    "   - At high temperatures, the algorithm frequently accepts worse solutions, allowing it to explore the search space broadly and escape local optima.\n",
    "   - As the temperature decreases, the algorithm becomes more selective, eventually only accepting improvements.\n",
    "The probability of accepting a worse solution is calculated using the formula:\n",
    "P(accept) = e^(-delta_D/T)\n",
    "Where:\n",
    "\n",
    "- delta_D is the increase in distance (how much worse the new solution is)\n",
    "- T is the current temperature\n",
    "This means:\n",
    "\n",
    "- When T is high, even large increases in distance have a good chance of being accepted\n",
    "- When T is low, only small increases have any chance of being accepted\n",
    "- As T approaches 0, the algorithm essentially becomes a hill climbing algorithm\n",
    "The temperature schedule (starting temperature T0, cooling rate alpha) is crucial for the algorithm's performance. If cooled too quickly, the algorithm may get stuck in local optima; if cooled too slowly, it may take too long to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution found: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Example distance matrix for 4 cities\n",
    "D = [\n",
    "    [0, 1, 2, 3],\n",
    "    [1, 0, 4, 5],\n",
    "    [2, 4, 0, 6],\n",
    "    [3, 5, 6, 0]\n",
    "]\n",
    "\n",
    "# Calculate the total distance of a tour\n",
    "def total_distance(tour):\n",
    "    n = len(tour)\n",
    "    dist = D[tour[-1]][tour[0]]\n",
    "    for i in range(n - 1):\n",
    "        dist += D[tour[i]][tour[i + 1]]\n",
    "    return dist\n",
    "\n",
    "# Generate a random initial tour\n",
    "def generate_initial_tour(n):\n",
    "    cities = list(range(n))\n",
    "    random.shuffle(cities)\n",
    "    return cities\n",
    "\n",
    "# Simulated Annealing Algorithm\n",
    "def simulated_annealing(T0, alpha, I):\n",
    "    n = len(D)\n",
    "    current_tour = generate_initial_tour(n)\n",
    "    best_tour = current_tour\n",
    "    T = T0\n",
    "    \n",
    "    for _ in range(I):\n",
    "        for _ in range(I):\n",
    "            candidate_tour = current_tour[:]\n",
    "            i, j = random.sample(range(n), 2)\n",
    "            candidate_tour[i], candidate_tour[j] = candidate_tour[j], candidate_tour[i]\n",
    "            \n",
    "            delta_D = total_distance(candidate_tour) - total_distance(current_tour)\n",
    "            if delta_D < 0 or random.random() < 1 / T:\n",
    "                current_tour = candidate_tour\n",
    "                if total_distance(candidate_tour) < total_distance(best_tour):\n",
    "                    best_tour = candidate_tour\n",
    "        \n",
    "        T *= alpha\n",
    "    \n",
    "    return best_tour\n",
    "\n",
    "# Example usage\n",
    "T0 = 1000\n",
    "alpha = 0.95\n",
    "I = 1000\n",
    "result = simulated_annealing(T0, alpha, I)\n",
    "print(f\"Best solution found: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
